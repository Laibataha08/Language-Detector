{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJs9qoTm83kp",
        "outputId": "48e87a2b-8f2f-404c-dd67-d5fff52cb2b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 62.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=ff8a492acf1fca75cae5d0e7d64ddd0d40378d3e52df5aa0a2d782a14db7cfe9\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pyspark.sql import SparkSession\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "spark=SparkSession.builder.appName('Practice').getOrCreate()\n",
        "spark\n",
        "df_pyspark= spark.read.csv('/content/languagedetections.csv',header=True)\n",
        "# df_pyspark.show()\n",
        "df_pyspark.columns\n",
        "df_pyspark.printSchema()\n",
        "print(\"Filling the missing values\")\n",
        "df_pyspark.na.fill('Missing Values').show()\n",
        "print(\"Grouping by language name \")\n",
        "df_pyspark.groupBy('language').sum().show()\n",
        "\n",
        "print(\"Creating RDDs\")\n",
        "rdd=df_pyspark.rdd\n",
        "rdd.collect()\n",
        "print(rdd.collect())\n",
        "\n",
        "X = df_pyspark.select('Text')\n",
        "Y = df_pyspark.select('language')\n",
        "x = np.array(X.collect())\n",
        "y = np.array(Y.collect())\n",
        "print(y.shape)\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(x.ravel())\n",
        "\n",
        "Y = y.ravel()\n",
        "model = MultinomialNB()\n",
        "model.fit(X,y)\n",
        "\n",
        "user = input(\"Enter a Text: \")\n",
        "data = cv.transform([user]).toarray()\n",
        "output = model.predict(data)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjBTkw2j-WTA",
        "outputId": "1f956baa-e05f-449d-b611-62dab9a43e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Text: string (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            "\n",
            "Filling the missing values\n",
            "+-------------------------------------+----------+\n",
            "|                                 Text|  language|\n",
            "+-------------------------------------+----------+\n",
            "|                 klement gottwaldi...|  Estonian|\n",
            "|                 sebes joseph pere...|   Swedish|\n",
            "|                 ถนนเจริญกรุง อักษ...|      Thai|\n",
            "|                 \"விசாகப்பட்டினம் ...|     Tamil|\n",
            "|                 de spons behoort ...|     Dutch|\n",
            "|エノが行きがかりでバスに乗ってしま...|  Japanese|\n",
            "|                 tsutinalar i̇ngil...|   Turkish|\n",
            "|                 müller mox figura...|     Latin|\n",
            "|                 برقی بار electric...|      Urdu|\n",
            "|シャーリー・フィールドは、サン・ベ...|  Japanese|\n",
            "|                 \"kemunculan perta...|Indonesian|\n",
            "|                 barocco pt escând...| Portugese|\n",
            "|                 association de re...|    French|\n",
            "|胡赛尼本人和小说的主人公阿米尔一样...|   Chinese|\n",
            "|   한국에서 성씨가 사용되기 시작한...|    Korean|\n",
            "|                 การฟาดฟันของบรรดา...|      Thai|\n",
            "|                 \"dorota rabczewsk...|  Estonian|\n",
            "|                 diante destes ger...| Portugese|\n",
            "|                 besemer s van der...| Portugese|\n",
            "|                 महाराष्ट्र  मई  क...|     Hindi|\n",
            "+-------------------------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Grouping by language name \n",
            "+----------+\n",
            "|  language|\n",
            "+----------+\n",
            "|      Urdu|\n",
            "|   Turkish|\n",
            "|     Latin|\n",
            "|   Persian|\n",
            "|      Thai|\n",
            "|    Pushto|\n",
            "|   Chinese|\n",
            "|Indonesian|\n",
            "|  Japanese|\n",
            "|   English|\n",
            "|   Spanish|\n",
            "|     Tamil|\n",
            "|  Estonian|\n",
            "|  Romanian|\n",
            "|   Russian|\n",
            "| Portugese|\n",
            "|    Korean|\n",
            "|     Hindi|\n",
            "|    French|\n",
            "|     Dutch|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Creating RDDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22000, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a Text: yellow\n",
            "['English']\n"
          ]
        }
      ]
    }
  ]
}